%%%%%%%%%%%%%%%%
%%% ABSTRACT %%%
%%%%%%%%%%%%%%%%
\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}

El creciente interés en la investigación de IA ha dado lugar a un enorme aumento en el tamaño de los modelos y en el coste computacional de su entrenamiento a lo largo de los últimos años. Dada la preocupación actual por el cambio climático y la necesidad de reducir emisiones de carbono, hallar formas de minimizar el impacto que la industria de la IA tiene sobre el medio ambiente es más importante que nunca.

El objetivo de este estudio es encontrar evidencias de que se puede utilizar un enfoque jerárquico en el aprendizaje por refuerzo profundo para reducir los costes de entrenamiento de agentes en entornos complejos al mismo tiempo que se mantiene el nivel de rendimiento del agente final. Para este fin, utilizamos StarCraft II como entorno de entrenamiento: un juego de estrategia en tiempo real que proporciona un enorme espacio de acciones y es fácil de utilizar para realizar experimentos de aprendizaje por refuerzo gracias a la librería PySC2.

\vspace{1.5cm}

\textbf{Keywords}: Aprendizaje por Refuerzo Profundo, Aprendizaje por Refuerzo Jerárquico, Eficiencia, Emisiones, StarCraft II