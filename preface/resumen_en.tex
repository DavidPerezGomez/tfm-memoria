%%%%%%%%%%%%%%%%
%%% ABSTRACT %%%
%%%%%%%%%%%%%%%%
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

The growing interest in AI research has led to a massive increase in model sizes and compute costs of their training over the last several years. With the current concerns about climate change and the necessity of reducing carbon emissions, finding ways to minimize the environmental impact of the AI industry is more important than ever.

The object of this study is to find evidence that a hierarchical approach to deep reinforcement learning can be used to reduce the costs of training agents in complex environments while maintaining the final agent performance. For this purpose, we use StarCraft II as the training environment: a popular real-time strategy game that affords a massive action space and is easy to use for reinforcement learning experiments thanks to the library PySC2.

\vspace{1.5cm}

\textbf{Keywords}: Deep Reinforcement Learning, Hierarchical Reinforcement Learning, Efficiency, Emissions, StarCraft II